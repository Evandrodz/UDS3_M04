{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subway Data Analysis\n",
    "\n",
    "## Introdução\n",
    "\n",
    "O sistema de ônibus e trens de Nova Iorque - o Metro Transit Authority - [fornece seus dados para download](http://web.mta.info/developers/developer-data-terms.html#data) através de  arquivos CSV. Dentre as informações disponíveis estão os **registros semanais de dados das catracas do metrô**. \n",
    "\n",
    "\n",
    "Estes registros contém contagens cumulativas das entradas e saídas, normalmente agrupadas em períodos de 4 horas, com dados adicionais que permitem identificar a estação e catraca específica correspondente a cada linha do arquivo. Neste projeto iremos utilizar um desses registros, mas não precisa baixar nada agora! O primeiro exercício será escrever um código Python para fazer isso por você :-)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sobre este projeto\n",
    "\n",
    "Neste projeto você irá aplicar todos os conhecimentos adquiridos neste primeiro mês de curso, com tarefas básicas de aquisição e limpeza de dados. No processo iremos descobrir informações essenciais sobre os dados, utilizando o que foi aprendido no curso de estatística. \n",
    "\n",
    "O objetivo deste projeto é explorar a relação entre os dados das catracas do metrô de Nova Iorque e o clima no dia da coleta. Para isso, além dos dados do metrô, precisaremos dos dados de clima da cidade de Nova Iorque. \n",
    "\n",
    "Os principais pontos que serão verificados neste trabalho:\n",
    "\n",
    "- Coleta de dados da internet\n",
    "- Utilização de estatística para análise de dados\n",
    "- Manipulação de dados e criação de gráficos simples com o `Pandas`\n",
    "\n",
    "*Como conseguir ajuda*: Sugerimos que busque apoio nos canais abaixo, na seguinte ordem de prioridade:\n",
    "\n",
    "| Tipo de dúvida\\Canais         \t| Google \t| Fórum \t| Slack \t| Email \t|\n",
    "|-------------------------------\t|--------\t|-------\t|-------\t|-------\t|\n",
    "| Programação Python e Pandas    \t| 1      \t| 2     \t| 3     \t|       \t|\n",
    "| Requisitos do projeto         \t|        \t| 1     \t| 2     \t| 3     \t|\n",
    "| Partes específicas do Projeto \t|        \t| 1     \t| 2     \t| 3     \t|\n",
    "\n",
    "Os endereços dos canais são:\n",
    "\n",
    "- Fórum: https://discussions.udacity.com/c/ndfdsi-project\n",
    "- Slack: [udacity-br.slack.com](https://udacity-br.slack.com/messages/C5MT6E3E1)\n",
    "- Email: data-suporte@udacity.com\n",
    "\n",
    "**Espera-se que o estudante entregue este relatório com:**\n",
    "\n",
    "- Todos os exercícios feitos, com atenção especial para os trechos de código a completar (sinalizados com `# your code here`), pois eles são essenciais para que o código rode corretamente\n",
    "- O arquivo ipynb exportado como HTML\n",
    "\n",
    "Para entregar este projeto envie este `.ipynb` preenchido e o HTML, zipados, na página correspondente da sala de aula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sobre o dataset\n",
    "\n",
    "Descrição das colunas\n",
    "<pre>\n",
    "C/A,UNIT,SCP,STATION,LINENAME,DIVISION,DATE,TIME,DESC,ENTRIES,EXITS\n",
    "  \n",
    "C/A      = Agrupamento de catracas de que a catraca faz parte (_Control Area_)\n",
    "UNIT     = Cabine de controle associada à estação onde a catraca se encontra (_Remote Unit for a station_)\n",
    "SCP      = Endereço específico da catraca (_Subunit Channel Position_)\n",
    "STATION  = Nome da estação onde a catraca se encontra\n",
    "LINENAME = Código representando todas linhas que passam na estação*\n",
    "DIVISION = Código representando a concessionária original da linha, antes da prefeitura assumir a gestão   \n",
    "DATE     = Representa a data (no formato MM-DD-YY) do evento de auditoria agendado\n",
    "TIME     = Representa o horário (hh:mm:ss) do evento de auditoria agendado\n",
    "DESc     = Descreve o tipo de evento de auditoria registrado:\n",
    "           1. \"REGULAR\" representando um evento de auditoria padrão, em que a contagem é feita a cada 4 horas\n",
    "           2. \"RECOVR AUD\" significa que o valor específico estava perdido, mas foi recuperado posteriormente \n",
    "           3. Diversos códigos sinalizam situações em que auditorias são mais frequentes devido a atividades de\n",
    "              planejamento ou solução de problemas. \n",
    "ENTRIES  = A contagem cumulativa de entradas associadas à catraca desde o último registro\n",
    "EXITS    = A contagem cumulativa de saídas associadas à catraca desde o último registro\n",
    "\n",
    "*  Normalmente as linhas são representadas por um caractere. LINENAME 456NQR significa que os trens 4, 5, 6, N, Q e R passam pela estação.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lembretes\n",
    "\n",
    "Antes de começarmos, alguns lembretes devem ter em mente ao usar os notebooks iPython:\n",
    "\n",
    "- Lembre-se de que você pode ver do lado esquerdo de uma célula de código quando foi executado pela última vez se houver um número dentro das chaves.\n",
    "- Quando você inicia uma nova sessão do notebook, certifique-se de executar todas as células até o ponto em que você deixou a última vez. Mesmo que a saída ainda seja visível a partir de quando você executou as células em sua sessão anterior, o kernel começa em um estado novo, então você precisará recarregar os dados, etc. em uma nova sessão.\n",
    "- O ponto anterior é útil para ter em mente se suas respostas não correspondem ao que é esperado nos questionários da aula. Tente recarregar os dados e execute todas as etapas de processamento um a um para garantir que você esteja trabalhando com as mesmas variáveis e dados que estão em cada fase do questionário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seção 1 - Coleta de Dados\n",
    "\n",
    "### *Exercicio 1.1*\n",
    "\n",
    "Mãos a obra!! Agora é sua vez de coletar os dados. Escreva abaixo um código python que acesse o link http://web.mta.info/developers/turnstile.html e baixe os arquivos do mês de junho de 2017. O arquivo deverá ser salvo com o nome turnstile_170610.txt onde 10/06/17 é a data do arquivo.\n",
    "\n",
    "<blockquote>\n",
    "    <p>Caso o site esteja fora do ar, use essa url:</p>\n",
    "    <p>https://s3.amazonaws.com/video.udacity-data.com/topher/2018/November/5bf32290_turnstile/turnstile.html</p>\n",
    "</blockquote>\n",
    "\n",
    "Abaixo seguem alguns comandos que poderão te ajudar:\n",
    "\n",
    "Utilize a biblioteca **urllib** para abrir e resgatar uma página da web. Utilize o comando abaixo onde **url** será o caminho da página da web onde se encontra o arquivo:\n",
    "\n",
    "```python\n",
    "u = urllib.urlopen(url)\n",
    "html = u.read()\n",
    "```\n",
    "\n",
    "Utilize a biblioteca **BeautifulSoup** para procurar na página pelo link do arquivo que deseja baixar. Utilize o comando abaixo para criar o seu objeto *soup* e procurar por todas as tags 'a'no documento:\n",
    " \n",
    " \n",
    "```python\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "links = soup.find_all('a')\n",
    "```\n",
    "\n",
    "Uma dica para baixar apenas os arquivos do mês de junho é verificar a data no nome do arquivo. Por exemplo, para baixar o arquivo do dia 17/06/2017 verifique se o link termina com *\"turnstile_170610.txt\"*. Se não fizer isso você baixará todos os arquivos da página. Para fazer isso utilize o comando conforme abaixo:\n",
    "\n",
    "```python\n",
    "if '1706' in link.get('href'):\n",
    "```\n",
    "\n",
    "E a dica final é utilizar o comando abaixo para fazer o download do arquivo txt:\n",
    "\n",
    "```python\n",
    "urllib.urlretrieve(link_do_arquivo, filename)\n",
    "```\n",
    "\n",
    "Lembre-se, primeiro, carregue todos os pacotes e funções que você estará usando em sua análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#your code here\n",
    "import sys\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other_url: https://s3.amazonaws.com/video.udacity-data.com/topher/2018/November/5bf32142_turnstile-170624/turnstile-170624.txt\n",
      "other_url: https://s3.amazonaws.com/video.udacity-data.com/topher/2018/November/5bf31e03_turnstile-170617/turnstile-170617.txt\n",
      "other_url: https://s3.amazonaws.com/video.udacity-data.com/topher/2018/November/5bf2fab0_turnstile-170610/turnstile-170610.txt\n",
      "other_url: https://s3.amazonaws.com/video.udacity-data.com/topher/2018/November/5bf31d11_turnstile-170603/turnstile-170603.txt\n"
     ]
    }
   ],
   "source": [
    "#Caminho padrão\n",
    "\n",
    "# path = \"http://web.mta.info/developers/\" Apresentando erro\n",
    "path = \"https://s3.amazonaws.com/video.udacity-data.com/topher/2018/November/5bf32290_turnstile/\"\n",
    "\n",
    "# URl principal\n",
    "#url = \"http://web.mta.info/developers/turnstile.html\" Apresentando erro\n",
    "url = \"https://s3.amazonaws.com/video.udacity-data.com/topher/2018/November/5bf32290_turnstile/turnstile.html\"\n",
    "    \n",
    "u = urllib.request.urlopen(url)\n",
    "html = u.read()\n",
    "\n",
    "# Parser do conteúdo\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "container = soup.find('div', { 'class': 'container'})\n",
    "links = container.find_all('a')\n",
    "\n",
    "for link in links:\n",
    "    link_str = str(link) \n",
    "    if '1706' in link_str and 'udacity' in link_str:\n",
    "        other_url = link.get('href')\n",
    " #       filename = other_url.split(\"/\")[-1]\n",
    " #       new_path = f\"{path}{other_url}\"\n",
    "        print(\"other_url:\", other_url)\n",
    " #       print(\"filename :\", filename) \n",
    " #       print(\"new_path :\", new_path)\n",
    "        urllib.request.urlretrieve(other_url)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercicio 1.2*\n",
    "\n",
    "Escreva uma função que pegue a lista de nomes dos arquivos que você baixou no exercicio 1.1 e consolide-os em um único arquivo. Deve existir apenas uma linha de cabeçalho no arquivo de saida. \n",
    "\n",
    "Por exemplo, se o arquivo_1 tiver:\n",
    "linha 1...\n",
    "linha 2...\n",
    "\n",
    "e o outro arquivo, arquivo_2 tiver:\n",
    "linha 3...\n",
    "linha 4...\n",
    "linha 5...\n",
    "\n",
    "Devemos combinar o arquivo_1 com arquivo_2 em um arquivo mestre conforme abaixo:\n",
    "\n",
    "'C/A, UNIT, SCP, DATEn, TIMEn, DESCn, ENTRIESn, EXITSn'\n",
    "linha 1...\n",
    "linha 2...\n",
    "linha 3...\n",
    "linha 4...\n",
    "linha 5...\n",
    "\n",
    "**OBS:** Note que algumas colunas foram descartadas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_master_turnstile_file(filenames, output_file):\n",
    "    with open(output_file, 'w') as master_file:\n",
    "        master_file.write('C/A,UNIT,SCP,DATEn,TIMEn,DESCn,ENTRIESn,EXITSn\\n')        \n",
    "        for filename in filenames:\n",
    "            # your code here            \n",
    "            #master_file.write(filename + '\\n') #- Para Teste\n",
    "            #line_count = 1 #- Para Teste\n",
    "            with open(filename) as partial_file:\n",
    "                for line in partial_file:  \n",
    "                    #Desconsidera a linha com cabeçalho \n",
    "                    if line.startswith(\"C/A\"):                         \n",
    "                        continue\n",
    "                    #if line_count > 1 and line_count <= 12: # Para teste\n",
    "                    # Separa linha para gerar linmha apenas com colunas relevantes \n",
    "                    fields = line.split(',')                        \n",
    "                    new_line = fields[0] + ',' + fields[1] + ',' + fields[2] + ',' + fields[6] + ',' + \\\n",
    "                               fields[7] + ',' + fields[8] + ',' + fields[9] + ',' + fields[10].rstrip() + '\\n' \n",
    "                    #print(new_line)                    \n",
    "                    #master_file.write(line)\n",
    "                    new_line\n",
    "                    master_file.write(new_line)\n",
    "                        \n",
    "                    #line_count += 1 # - Para teste\n",
    "\n",
    "days = ['03', '10', '17', '24']\n",
    "filenames = []\n",
    "for d in days:\n",
    "    filenames.append(f\"turnstile-1706{d}.txt\")\n",
    "\n",
    "create_master_turnstile_file(filenames, \"master_turnstile_201706.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercicio 1.3*\n",
    "\n",
    "Neste exercício, escreva um função que leia o master_file criado no exercicio anterior e carregue-o em um pandas dataframe. Esta função deve filtrar para que o dataframe possua apenas linhas onde a coluna \"DESCn\" possua o valor \"Regular\".\n",
    "\n",
    "Por exemplo, se o data frame do pandas estiver conforme abaixo:\n",
    "    \n",
    "    ,C/A,UNIT,SCP,DATEn,TIMEn,DESCn,ENTRIESn,EXITSn\n",
    "    0,A002,R051,02-00-00,05-01-11,00:00:00,REGULAR,3144312,1088151\n",
    "    1,A002,R051,02-00-00,05-01-11,04:00:00,DOOR,3144335,1088159\n",
    "    2,A002,R051,02-00-00,05-01-11,08:00:00,REGULAR,3144353,1088177\n",
    "    3,A002,R051,02-00-00,05-01-11,12:00:00,DOOR,3144424,1088231\n",
    "\n",
    "O dataframe deverá ficar conforme abaixo depois de filtrar apenas as linhas onde a coluna DESCn possua o valor REGULAR:\n",
    "\n",
    "    0,A002,R051,02-00-00,05-01-11,00:00:00,REGULAR,3144312,1088151\n",
    "    2,A002,R051,02-00-00,05-01-11,08:00:00,REGULAR,3144353,1088177\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "\n",
    "def filter_by_regular(filename):\n",
    "    \n",
    "    turnstile_data = pd.read_csv(filename)\n",
    "    # more of your code here\n",
    "    turnstile_data = turnstile_data[turnstile_data.DESCn=='REGULAR']\n",
    "    return turnstile_data\n",
    "\n",
    "df_turnstile_reg = filter_by_regular('master_turnstile_201706.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercicio 1.4*\n",
    "\n",
    "\n",
    "Os dados do metrô de NY possui dados cumulativos de entradas e saidas por linha. Assuma que você possui um dataframe chamado df que contém apenas linhas para uma catraca em particular (unico SCP, C/A, e UNIT). A função abaixo deve alterar essas entradas cumulativas para a contagem de entradas desde a última leitura (entradas desde a última linha do dataframe).\n",
    "\n",
    "Mais especificamente, você deverá fazer duas coisas:\n",
    "\n",
    "1. Criar uma nova coluna chamada ENTRIESn_hourly\n",
    "\n",
    "2. Inserir nessa coluna a diferença entre ENTRIESn da linha atual e a da linha anterior. Se a linha possuir alguma NAN, preencha/substitua por 1.\n",
    "\n",
    "Dica: as funções do pandas shift() e fillna() pode ser úteis nesse exercicio.\n",
    "\n",
    "Abaixo tem um exemplo de como seu dataframe deve ficar ao final desse exercicio:\n",
    "\n",
    "           C/A  UNIT       SCP     DATEn     TIMEn    DESCn  ENTRIESn    EXITSn  ENTRIESn_hourly\n",
    "    0     A002  R051  02-00-00  05-01-11  00:00:00  REGULAR   3144312   1088151                1\n",
    "    1     A002  R051  02-00-00  05-01-11  04:00:00  REGULAR   3144335   1088159               23\n",
    "    2     A002  R051  02-00-00  05-01-11  08:00:00  REGULAR   3144353   1088177               18\n",
    "    3     A002  R051  02-00-00  05-01-11  12:00:00  REGULAR   3144424   1088231               71\n",
    "    4     A002  R051  02-00-00  05-01-11  16:00:00  REGULAR   3144594   1088275              170\n",
    "    5     A002  R051  02-00-00  05-01-11  20:00:00  REGULAR   3144808   1088317              214\n",
    "    6     A002  R051  02-00-00  05-02-11  00:00:00  REGULAR   3144895   1088328               87\n",
    "    7     A002  R051  02-00-00  05-02-11  04:00:00  REGULAR   3144905   1088331               10\n",
    "    8     A002  R051  02-00-00  05-02-11  08:00:00  REGULAR   3144941   1088420               36\n",
    "    9     A002  R051  02-00-00  05-02-11  12:00:00  REGULAR   3145094   1088753              153\n",
    "    10    A002  R051  02-00-00  05-02-11  16:00:00  REGULAR   3145337   1088823              243"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 785406 entries, 0 to 788213\n",
      "Data columns (total 8 columns):\n",
      "C/A         785406 non-null object\n",
      "UNIT        785406 non-null object\n",
      "SCP         785406 non-null object\n",
      "DATEn       785406 non-null object\n",
      "TIMEn       785406 non-null object\n",
      "DESCn       785406 non-null object\n",
      "ENTRIESn    785406 non-null int64\n",
      "EXITSn      785406 non-null int64\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 53.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_turnstile_reg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C/A</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>SCP</th>\n",
       "      <th>DATEn</th>\n",
       "      <th>TIMEn</th>\n",
       "      <th>DESCn</th>\n",
       "      <th>ENTRIESn</th>\n",
       "      <th>EXITSn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>05/27/2017</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6195217</td>\n",
       "      <td>2098317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>05/27/2017</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6195240</td>\n",
       "      <td>2098318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>05/27/2017</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6195256</td>\n",
       "      <td>2098347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>05/27/2017</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6195346</td>\n",
       "      <td>2098432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>05/27/2017</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6195518</td>\n",
       "      <td>2098491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>05/27/2017</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6195765</td>\n",
       "      <td>2098537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>05/28/2017</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6195898</td>\n",
       "      <td>2098559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>05/28/2017</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6195914</td>\n",
       "      <td>2098562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>05/28/2017</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6195930</td>\n",
       "      <td>2098581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>05/28/2017</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6196024</td>\n",
       "      <td>2098646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    C/A  UNIT       SCP       DATEn     TIMEn    DESCn  ENTRIESn   EXITSn\n",
       "0  A002  R051  02-00-00  05/27/2017  00:00:00  REGULAR   6195217  2098317\n",
       "1  A002  R051  02-00-00  05/27/2017  04:00:00  REGULAR   6195240  2098318\n",
       "2  A002  R051  02-00-00  05/27/2017  08:00:00  REGULAR   6195256  2098347\n",
       "3  A002  R051  02-00-00  05/27/2017  12:00:00  REGULAR   6195346  2098432\n",
       "4  A002  R051  02-00-00  05/27/2017  16:00:00  REGULAR   6195518  2098491\n",
       "5  A002  R051  02-00-00  05/27/2017  20:00:00  REGULAR   6195765  2098537\n",
       "6  A002  R051  02-00-00  05/28/2017  00:00:00  REGULAR   6195898  2098559\n",
       "7  A002  R051  02-00-00  05/28/2017  04:00:00  REGULAR   6195914  2098562\n",
       "8  A002  R051  02-00-00  05/28/2017  08:00:00  REGULAR   6195930  2098581\n",
       "9  A002  R051  02-00-00  05/28/2017  12:00:00  REGULAR   6196024  2098646"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_turnstile_reg.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas\n",
    "\n",
    "def get_hourly_entries(df):    \n",
    "    \n",
    "    #your code here    \n",
    "    diff_ENTRIESn = pd.to_numeric(df['ENTRIESn']) - pd.to_numeric(df['ENTRIESn'].shift(1))\n",
    "    #print(diff_ENTRIESn)\n",
    "    df['ENTRIESn_hourly'] = diff_ENTRIESn.fillna(1).astype(int) \n",
    "    \n",
    "    return df\n",
    "\n",
    "df_h_entries = get_hourly_entries(df_turnstile_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          C/A  UNIT       SCP       DATEn     TIMEn    DESCn  ENTRIESn  \\\n",
      "0        A002  R051  02-00-00  05/27/2017  00:00:00  REGULAR   6195217   \n",
      "1        A002  R051  02-00-00  05/27/2017  04:00:00  REGULAR   6195240   \n",
      "2        A002  R051  02-00-00  05/27/2017  08:00:00  REGULAR   6195256   \n",
      "3        A002  R051  02-00-00  05/27/2017  12:00:00  REGULAR   6195346   \n",
      "4        A002  R051  02-00-00  05/27/2017  16:00:00  REGULAR   6195518   \n",
      "5        A002  R051  02-00-00  05/27/2017  20:00:00  REGULAR   6195765   \n",
      "6        A002  R051  02-00-00  05/28/2017  00:00:00  REGULAR   6195898   \n",
      "7        A002  R051  02-00-00  05/28/2017  04:00:00  REGULAR   6195914   \n",
      "8        A002  R051  02-00-00  05/28/2017  08:00:00  REGULAR   6195930   \n",
      "9        A002  R051  02-00-00  05/28/2017  12:00:00  REGULAR   6196024   \n",
      "10       A002  R051  02-00-00  05/28/2017  16:00:00  REGULAR   6196186   \n",
      "11       A002  R051  02-00-00  05/28/2017  20:00:00  REGULAR   6196446   \n",
      "12       A002  R051  02-00-00  05/29/2017  00:00:00  REGULAR   6196569   \n",
      "13       A002  R051  02-00-00  05/29/2017  04:00:00  REGULAR   6196587   \n",
      "14       A002  R051  02-00-00  05/29/2017  08:00:00  REGULAR   6196597   \n",
      "15       A002  R051  02-00-00  05/29/2017  12:00:00  REGULAR   6196666   \n",
      "16       A002  R051  02-00-00  05/29/2017  16:00:00  REGULAR   6196853   \n",
      "17       A002  R051  02-00-00  05/29/2017  20:00:00  REGULAR   6197107   \n",
      "18       A002  R051  02-00-00  05/30/2017  00:00:00  REGULAR   6197230   \n",
      "19       A002  R051  02-00-00  05/30/2017  04:00:00  REGULAR   6197238   \n",
      "20       A002  R051  02-00-00  05/30/2017  08:00:00  REGULAR   6197288   \n",
      "21       A002  R051  02-00-00  05/30/2017  12:00:00  REGULAR   6197470   \n",
      "22       A002  R051  02-00-00  05/30/2017  16:00:00  REGULAR   6197790   \n",
      "23       A002  R051  02-00-00  05/30/2017  20:00:00  REGULAR   6198624   \n",
      "24       A002  R051  02-00-00  05/31/2017  00:00:00  REGULAR   6198819   \n",
      "25       A002  R051  02-00-00  05/31/2017  04:00:00  REGULAR   6198834   \n",
      "26       A002  R051  02-00-00  05/31/2017  08:00:00  REGULAR   6198880   \n",
      "27       A002  R051  02-00-00  05/31/2017  12:00:00  REGULAR   6199053   \n",
      "28       A002  R051  02-00-00  05/31/2017  16:00:00  REGULAR   6199379   \n",
      "29       A002  R051  02-00-00  05/31/2017  20:00:00  REGULAR   6200200   \n",
      "...       ...   ...       ...         ...       ...      ...       ...   \n",
      "788184  TRAM2  R469  00-05-01  06/19/2017  01:00:00  REGULAR      5554   \n",
      "788185  TRAM2  R469  00-05-01  06/19/2017  05:00:00  REGULAR      5554   \n",
      "788186  TRAM2  R469  00-05-01  06/19/2017  09:00:00  REGULAR      5554   \n",
      "788187  TRAM2  R469  00-05-01  06/19/2017  13:00:00  REGULAR      5554   \n",
      "788188  TRAM2  R469  00-05-01  06/19/2017  17:00:00  REGULAR      5554   \n",
      "788189  TRAM2  R469  00-05-01  06/19/2017  21:00:00  REGULAR      5554   \n",
      "788190  TRAM2  R469  00-05-01  06/20/2017  01:00:00  REGULAR      5554   \n",
      "788191  TRAM2  R469  00-05-01  06/20/2017  05:00:00  REGULAR      5554   \n",
      "788192  TRAM2  R469  00-05-01  06/20/2017  09:00:00  REGULAR      5554   \n",
      "788193  TRAM2  R469  00-05-01  06/20/2017  13:00:00  REGULAR      5554   \n",
      "788194  TRAM2  R469  00-05-01  06/20/2017  17:00:00  REGULAR      5554   \n",
      "788195  TRAM2  R469  00-05-01  06/20/2017  21:00:00  REGULAR      5554   \n",
      "788196  TRAM2  R469  00-05-01  06/21/2017  01:00:00  REGULAR      5554   \n",
      "788197  TRAM2  R469  00-05-01  06/21/2017  05:00:00  REGULAR      5554   \n",
      "788198  TRAM2  R469  00-05-01  06/21/2017  09:00:00  REGULAR      5554   \n",
      "788199  TRAM2  R469  00-05-01  06/21/2017  13:00:00  REGULAR      5554   \n",
      "788200  TRAM2  R469  00-05-01  06/21/2017  17:00:00  REGULAR      5554   \n",
      "788201  TRAM2  R469  00-05-01  06/21/2017  21:00:00  REGULAR      5554   \n",
      "788202  TRAM2  R469  00-05-01  06/22/2017  01:00:00  REGULAR      5554   \n",
      "788203  TRAM2  R469  00-05-01  06/22/2017  05:00:00  REGULAR      5554   \n",
      "788204  TRAM2  R469  00-05-01  06/22/2017  09:00:00  REGULAR      5554   \n",
      "788205  TRAM2  R469  00-05-01  06/22/2017  13:00:00  REGULAR      5554   \n",
      "788206  TRAM2  R469  00-05-01  06/22/2017  17:00:00  REGULAR      5554   \n",
      "788207  TRAM2  R469  00-05-01  06/22/2017  21:00:00  REGULAR      5554   \n",
      "788208  TRAM2  R469  00-05-01  06/23/2017  01:00:00  REGULAR      5554   \n",
      "788209  TRAM2  R469  00-05-01  06/23/2017  05:00:00  REGULAR      5554   \n",
      "788210  TRAM2  R469  00-05-01  06/23/2017  09:00:00  REGULAR      5554   \n",
      "788211  TRAM2  R469  00-05-01  06/23/2017  13:00:00  REGULAR      5554   \n",
      "788212  TRAM2  R469  00-05-01  06/23/2017  17:00:00  REGULAR      5554   \n",
      "788213  TRAM2  R469  00-05-01  06/23/2017  21:00:00  REGULAR      5554   \n",
      "\n",
      "         EXITSn  ENTRIESn_hourly  \n",
      "0       2098317                1  \n",
      "1       2098318               23  \n",
      "2       2098347               16  \n",
      "3       2098432               90  \n",
      "4       2098491              172  \n",
      "5       2098537              247  \n",
      "6       2098559              133  \n",
      "7       2098562               16  \n",
      "8       2098581               16  \n",
      "9       2098646               94  \n",
      "10      2098685              162  \n",
      "11      2098723              260  \n",
      "12      2098745              123  \n",
      "13      2098747               18  \n",
      "14      2098766               10  \n",
      "15      2098845               69  \n",
      "16      2098891              187  \n",
      "17      2098922              254  \n",
      "18      2098946              123  \n",
      "19      2098949                8  \n",
      "20      2099066               50  \n",
      "21      2099345              182  \n",
      "22      2099442              320  \n",
      "23      2099521              834  \n",
      "24      2099552              195  \n",
      "25      2099555               15  \n",
      "26      2099671               46  \n",
      "27      2099950              173  \n",
      "28      2100021              326  \n",
      "29      2100072              821  \n",
      "...         ...              ...  \n",
      "788184      301                0  \n",
      "788185      301                0  \n",
      "788186      301                0  \n",
      "788187      301                0  \n",
      "788188      301                0  \n",
      "788189      301                0  \n",
      "788190      301                0  \n",
      "788191      301                0  \n",
      "788192      301                0  \n",
      "788193      301                0  \n",
      "788194      301                0  \n",
      "788195      301                0  \n",
      "788196      301                0  \n",
      "788197      301                0  \n",
      "788198      301                0  \n",
      "788199      301                0  \n",
      "788200      301                0  \n",
      "788201      301                0  \n",
      "788202      301                0  \n",
      "788203      301                0  \n",
      "788204      301                0  \n",
      "788205      301                0  \n",
      "788206      301                0  \n",
      "788207      301                0  \n",
      "788208      301                0  \n",
      "788209      301                0  \n",
      "788210      301                0  \n",
      "788211      301                0  \n",
      "788212      301                0  \n",
      "788213      301                0  \n",
      "\n",
      "[785406 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_h_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercicio 1.5*\n",
    "\n",
    "Faça o mesmo do exercicio anterior mas agora considerando as saidas, coluna EXITSn.\n",
    "Para isso crie uma coluna chamada de EXITSn_hourly e insira a diferença entre a coluna EXITSn da linha atual versus a linha anterior. Se tiver algum NaN, preencha/substitua por 0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas\n",
    "\n",
    "def get_hourly_exits(df):\n",
    "    \n",
    "    #your code here\n",
    "    diff_EXITSn = pd.to_numeric(df['EXITSn']) - pd.to_numeric(df['EXITSn'].shift(1))\n",
    "    #print(diff_EXITSn)\n",
    "    df['EXITSn_hourly'] = diff_EXITSn.fillna(0).astype(int) \n",
    "    \n",
    "    return df\n",
    "\n",
    "df_h_exits = get_hourly_exits(df_h_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          C/A  UNIT       SCP       DATEn     TIMEn    DESCn  ENTRIESn  \\\n",
      "0        A002  R051  02-00-00  05/27/2017  00:00:00  REGULAR   6195217   \n",
      "1        A002  R051  02-00-00  05/27/2017  04:00:00  REGULAR   6195240   \n",
      "2        A002  R051  02-00-00  05/27/2017  08:00:00  REGULAR   6195256   \n",
      "3        A002  R051  02-00-00  05/27/2017  12:00:00  REGULAR   6195346   \n",
      "4        A002  R051  02-00-00  05/27/2017  16:00:00  REGULAR   6195518   \n",
      "5        A002  R051  02-00-00  05/27/2017  20:00:00  REGULAR   6195765   \n",
      "6        A002  R051  02-00-00  05/28/2017  00:00:00  REGULAR   6195898   \n",
      "7        A002  R051  02-00-00  05/28/2017  04:00:00  REGULAR   6195914   \n",
      "8        A002  R051  02-00-00  05/28/2017  08:00:00  REGULAR   6195930   \n",
      "9        A002  R051  02-00-00  05/28/2017  12:00:00  REGULAR   6196024   \n",
      "10       A002  R051  02-00-00  05/28/2017  16:00:00  REGULAR   6196186   \n",
      "11       A002  R051  02-00-00  05/28/2017  20:00:00  REGULAR   6196446   \n",
      "12       A002  R051  02-00-00  05/29/2017  00:00:00  REGULAR   6196569   \n",
      "13       A002  R051  02-00-00  05/29/2017  04:00:00  REGULAR   6196587   \n",
      "14       A002  R051  02-00-00  05/29/2017  08:00:00  REGULAR   6196597   \n",
      "15       A002  R051  02-00-00  05/29/2017  12:00:00  REGULAR   6196666   \n",
      "16       A002  R051  02-00-00  05/29/2017  16:00:00  REGULAR   6196853   \n",
      "17       A002  R051  02-00-00  05/29/2017  20:00:00  REGULAR   6197107   \n",
      "18       A002  R051  02-00-00  05/30/2017  00:00:00  REGULAR   6197230   \n",
      "19       A002  R051  02-00-00  05/30/2017  04:00:00  REGULAR   6197238   \n",
      "20       A002  R051  02-00-00  05/30/2017  08:00:00  REGULAR   6197288   \n",
      "21       A002  R051  02-00-00  05/30/2017  12:00:00  REGULAR   6197470   \n",
      "22       A002  R051  02-00-00  05/30/2017  16:00:00  REGULAR   6197790   \n",
      "23       A002  R051  02-00-00  05/30/2017  20:00:00  REGULAR   6198624   \n",
      "24       A002  R051  02-00-00  05/31/2017  00:00:00  REGULAR   6198819   \n",
      "25       A002  R051  02-00-00  05/31/2017  04:00:00  REGULAR   6198834   \n",
      "26       A002  R051  02-00-00  05/31/2017  08:00:00  REGULAR   6198880   \n",
      "27       A002  R051  02-00-00  05/31/2017  12:00:00  REGULAR   6199053   \n",
      "28       A002  R051  02-00-00  05/31/2017  16:00:00  REGULAR   6199379   \n",
      "29       A002  R051  02-00-00  05/31/2017  20:00:00  REGULAR   6200200   \n",
      "...       ...   ...       ...         ...       ...      ...       ...   \n",
      "788184  TRAM2  R469  00-05-01  06/19/2017  01:00:00  REGULAR      5554   \n",
      "788185  TRAM2  R469  00-05-01  06/19/2017  05:00:00  REGULAR      5554   \n",
      "788186  TRAM2  R469  00-05-01  06/19/2017  09:00:00  REGULAR      5554   \n",
      "788187  TRAM2  R469  00-05-01  06/19/2017  13:00:00  REGULAR      5554   \n",
      "788188  TRAM2  R469  00-05-01  06/19/2017  17:00:00  REGULAR      5554   \n",
      "788189  TRAM2  R469  00-05-01  06/19/2017  21:00:00  REGULAR      5554   \n",
      "788190  TRAM2  R469  00-05-01  06/20/2017  01:00:00  REGULAR      5554   \n",
      "788191  TRAM2  R469  00-05-01  06/20/2017  05:00:00  REGULAR      5554   \n",
      "788192  TRAM2  R469  00-05-01  06/20/2017  09:00:00  REGULAR      5554   \n",
      "788193  TRAM2  R469  00-05-01  06/20/2017  13:00:00  REGULAR      5554   \n",
      "788194  TRAM2  R469  00-05-01  06/20/2017  17:00:00  REGULAR      5554   \n",
      "788195  TRAM2  R469  00-05-01  06/20/2017  21:00:00  REGULAR      5554   \n",
      "788196  TRAM2  R469  00-05-01  06/21/2017  01:00:00  REGULAR      5554   \n",
      "788197  TRAM2  R469  00-05-01  06/21/2017  05:00:00  REGULAR      5554   \n",
      "788198  TRAM2  R469  00-05-01  06/21/2017  09:00:00  REGULAR      5554   \n",
      "788199  TRAM2  R469  00-05-01  06/21/2017  13:00:00  REGULAR      5554   \n",
      "788200  TRAM2  R469  00-05-01  06/21/2017  17:00:00  REGULAR      5554   \n",
      "788201  TRAM2  R469  00-05-01  06/21/2017  21:00:00  REGULAR      5554   \n",
      "788202  TRAM2  R469  00-05-01  06/22/2017  01:00:00  REGULAR      5554   \n",
      "788203  TRAM2  R469  00-05-01  06/22/2017  05:00:00  REGULAR      5554   \n",
      "788204  TRAM2  R469  00-05-01  06/22/2017  09:00:00  REGULAR      5554   \n",
      "788205  TRAM2  R469  00-05-01  06/22/2017  13:00:00  REGULAR      5554   \n",
      "788206  TRAM2  R469  00-05-01  06/22/2017  17:00:00  REGULAR      5554   \n",
      "788207  TRAM2  R469  00-05-01  06/22/2017  21:00:00  REGULAR      5554   \n",
      "788208  TRAM2  R469  00-05-01  06/23/2017  01:00:00  REGULAR      5554   \n",
      "788209  TRAM2  R469  00-05-01  06/23/2017  05:00:00  REGULAR      5554   \n",
      "788210  TRAM2  R469  00-05-01  06/23/2017  09:00:00  REGULAR      5554   \n",
      "788211  TRAM2  R469  00-05-01  06/23/2017  13:00:00  REGULAR      5554   \n",
      "788212  TRAM2  R469  00-05-01  06/23/2017  17:00:00  REGULAR      5554   \n",
      "788213  TRAM2  R469  00-05-01  06/23/2017  21:00:00  REGULAR      5554   \n",
      "\n",
      "         EXITSn  ENTRIESn_hourly  EXITSn_hourly  \n",
      "0       2098317                1              0  \n",
      "1       2098318               23              1  \n",
      "2       2098347               16             29  \n",
      "3       2098432               90             85  \n",
      "4       2098491              172             59  \n",
      "5       2098537              247             46  \n",
      "6       2098559              133             22  \n",
      "7       2098562               16              3  \n",
      "8       2098581               16             19  \n",
      "9       2098646               94             65  \n",
      "10      2098685              162             39  \n",
      "11      2098723              260             38  \n",
      "12      2098745              123             22  \n",
      "13      2098747               18              2  \n",
      "14      2098766               10             19  \n",
      "15      2098845               69             79  \n",
      "16      2098891              187             46  \n",
      "17      2098922              254             31  \n",
      "18      2098946              123             24  \n",
      "19      2098949                8              3  \n",
      "20      2099066               50            117  \n",
      "21      2099345              182            279  \n",
      "22      2099442              320             97  \n",
      "23      2099521              834             79  \n",
      "24      2099552              195             31  \n",
      "25      2099555               15              3  \n",
      "26      2099671               46            116  \n",
      "27      2099950              173            279  \n",
      "28      2100021              326             71  \n",
      "29      2100072              821             51  \n",
      "...         ...              ...            ...  \n",
      "788184      301                0              0  \n",
      "788185      301                0              0  \n",
      "788186      301                0              0  \n",
      "788187      301                0              0  \n",
      "788188      301                0              0  \n",
      "788189      301                0              0  \n",
      "788190      301                0              0  \n",
      "788191      301                0              0  \n",
      "788192      301                0              0  \n",
      "788193      301                0              0  \n",
      "788194      301                0              0  \n",
      "788195      301                0              0  \n",
      "788196      301                0              0  \n",
      "788197      301                0              0  \n",
      "788198      301                0              0  \n",
      "788199      301                0              0  \n",
      "788200      301                0              0  \n",
      "788201      301                0              0  \n",
      "788202      301                0              0  \n",
      "788203      301                0              0  \n",
      "788204      301                0              0  \n",
      "788205      301                0              0  \n",
      "788206      301                0              0  \n",
      "788207      301                0              0  \n",
      "788208      301                0              0  \n",
      "788209      301                0              0  \n",
      "788210      301                0              0  \n",
      "788211      301                0              0  \n",
      "788212      301                0              0  \n",
      "788213      301                0              0  \n",
      "\n",
      "[785406 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_h_exits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 785406 entries, 0 to 788213\n",
      "Data columns (total 10 columns):\n",
      "C/A                785406 non-null object\n",
      "UNIT               785406 non-null object\n",
      "SCP                785406 non-null object\n",
      "DATEn              785406 non-null object\n",
      "TIMEn              785406 non-null object\n",
      "DESCn              785406 non-null object\n",
      "ENTRIESn           785406 non-null int64\n",
      "EXITSn             785406 non-null int64\n",
      "ENTRIESn_hourly    785406 non-null int32\n",
      "EXITSn_hourly      785406 non-null int32\n",
      "dtypes: int32(2), int64(2), object(6)\n",
      "memory usage: 59.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_h_exits.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercicio 1.6*\n",
    "\n",
    "Dado uma variável de entrada que representa o tempo no formato de:\n",
    "     \"00:00:00\" (hora: minutos: segundos)\n",
    "    \n",
    "Escreva uma função para extrair a parte da hora do tempo variável de entrada\n",
    "E devolva-o como um número inteiro. Por exemplo:\n",
    "         \n",
    "         1) se a hora for 00, seu código deve retornar 0\n",
    "         2) se a hora for 01, seu código deve retornar 1\n",
    "         3) se a hora for 21, seu código deve retornar 21\n",
    "        \n",
    "Por favor, devolva a hora como um número inteiro.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_hour(time):    \n",
    "    hour = int(time.split(':')[0])\n",
    "    return hour\n",
    "\n",
    "df_h_exits['HOUR'] = df_h_exits['TIMEn'].map(lambda x: time_to_hour(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 785406 entries, 0 to 788213\n",
      "Data columns (total 11 columns):\n",
      "C/A                785406 non-null object\n",
      "UNIT               785406 non-null object\n",
      "SCP                785406 non-null object\n",
      "DATEn              785406 non-null object\n",
      "TIMEn              785406 non-null object\n",
      "DESCn              785406 non-null object\n",
      "ENTRIESn           785406 non-null int64\n",
      "EXITSn             785406 non-null int64\n",
      "ENTRIESn_hourly    785406 non-null int32\n",
      "EXITSn_hourly      785406 non-null int32\n",
      "HOUR               785406 non-null int64\n",
      "dtypes: int32(2), int64(3), object(6)\n",
      "memory usage: 65.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_h_exits.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercicio 2 - Análise dos dados\n",
    "\n",
    "### *Exercicio 2.1*\n",
    "\n",
    "Para verificar a relação entre o movimento do metrô e o clima, precisaremos complementar os dados do arquivo já baixado com os dados do clima.\n",
    "Nós complementamos para você este arquivo com os dados de clima de Nova Iorque  e disponibilizamos na área de materiais do projeto. Você pode acessa-lo pelo link: https://s3.amazonaws.com/content.udacity-data.com/courses/ud359/turnstile_data_master_with_weather.csv\n",
    "\n",
    "Agora que temos nossos dados em um arquivo csv, escreva um código python que leia este arquivo e salve-o em um data frame do pandas. \n",
    "\n",
    "Dica: \n",
    "\n",
    "Utilize o comando abaixo para ler o arquivo:\n",
    "\n",
    "```python\n",
    "pd.read_csv('output_list.txt', sep=\",\")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "\n",
    "filename = \"turnstile_data_master_with_weather.csv\"\n",
    "\n",
    "#your code here\n",
    "df_weather = pd.read_csv(filename, sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercicio 2.2*\n",
    "\n",
    "Agora crie uma função que calcule a quantidade de dias chuvosos, para isso retorne a contagem do numero de dias onde a coluna *\"rain\"* é igual a 1.\n",
    "\n",
    "Dica: Você também pode achar que a interpretação de números como números inteiros ou float pode não\n",
    "     funcionar inicialmente. Para contornar esta questão, pode ser útil converter\n",
    "     esses números para números inteiros. Isso pode ser feito escrevendo cast (coluna como inteiro).\n",
    "     Então, por exemplo, se queríamos lançar a coluna maxtempi como um número inteiro, nós devemos\n",
    "     escrever algo como cast (maxtempi as integer) = 76, em oposição a simplesmente\n",
    "     onde maxtempi = 76."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def num_rainy_days(df):\n",
    "    \n",
    "    #your code here\n",
    "    df['rain'] = pd.to_numeric(df['rain'])\n",
    "    num_days = len(df[df.rain == 1].groupby('DATEn'))\n",
    "    \n",
    "    return num_days\n",
    "\n",
    "num_days_rainy = num_rainy_days(df_weather)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(num_days_rainy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercicio 2.3*\n",
    "\n",
    "Calcule se estava nebuloso ou não (0 ou 1) e a temperatura máxima para fog (isto é, a temperatura máxima \n",
    "     para dias nebulosos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fog\n",
       "0    86.0\n",
       "1    81.0\n",
       "Name: maxtempi, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_temp_aggregate_by_fog(df):\n",
    "    \n",
    "    #Converte fog para numero inteiro \n",
    "    df['fog'] = pd.to_numeric(df['fog'], errors='coerce').fillna(0).astype(np.int64)    \n",
    "    \n",
    "    #df.groupby(['fog'])['maxtempi'].count()    \n",
    "    #print(df.groupby(['fog'])['maxtempi'].count())\n",
    "    \n",
    "    max_tmp = df.groupby(['fog'])['maxtempi'].max()\n",
    "    \n",
    "    return max_tmp\n",
    "    \n",
    "max_temp_aggregate_by_fog(df_weather)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercicio 2.4\n",
    "\n",
    "Calcule agora a média de 'meantempi' nos dias que são sábado ou domingo (finais de semana):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'65.10'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def avg_weekend_temperature(filename):\n",
    "    \n",
    "    df_avg = pd.read_csv(filename, sep=',')\n",
    "    df_avg['weekday'] = pd.to_datetime(df_avg['DATEn']).dt.dayofweek\n",
    "    filtered_data = df_avg['meantempi'].astype(float)[df_avg['weekday'] >= 5]\n",
    "    \n",
    "    mean_temp_weekends = (\"%.2f\" % filtered_data.mean())\n",
    "    \n",
    "    return mean_temp_weekends\n",
    "\n",
    "avg_weekend_temperature('turnstile_data_master_with_weather.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercicio 2.5\n",
    "\n",
    "Calcule a média da temperatura mínima 'mintempi' nos dias chuvosos onde da temperatura mínima foi maior que do 55 graus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'61.24'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def avg_min_temperature(filename):\n",
    "    df = pd.read_csv(filename, dtype=object)\n",
    "    filtered_data = df['mintempi'].astype(float)[df['rain'] == '1.0'][df['mintempi'].astype(float) > 55]\n",
    "    avg_mintemp_on_rainy_days = filtered_data.mean()\n",
    "    \n",
    "    avg_min_temp_rainy = (\"%.2f\" % avg_mintemp_on_rainy_days)\n",
    "    \n",
    "    return avg_min_temp_rainy\n",
    "\n",
    "avg_min_temperature('turnstile_data_master_with_weather.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercicio 2.6\n",
    "\n",
    "Antes de realizar qualquer análise, pode ser útil olhar para os dados que esperamos analisar. Mais especificamente, vamos examinR as entradas por hora em nossos dados do metrô de Nova York para determinar a distribuição dos dados. Estes dados são armazenados na coluna ['ENTRIESn_hourly'].\n",
    "    \n",
    "Trace dois histogramas nos mesmos eixos para mostrar as entradas quando esta chovendo vs quando não está chovendo. \n",
    "Abaixo está um exemplo sobre como traçar histogramas com pandas e matplotlib:\n",
    "     \n",
    "```python\n",
    "Turnstile_weather ['column_to_graph']. Hist ()\n",
    "```   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from 'C:\\\\Users\\\\evand\\\\Anaconda3\\\\lib\\\\site-packages\\\\matplotlib\\\\pyplot.py'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "def entries_histogram(turnstile_weather):\n",
    "       \n",
    "    \n",
    "    plt.figure()\n",
    "    turnstile_weather[turnstile_weather['rain'] == 0]['ENTRIESn_hourly'].hist(alpha=0.45, label=\"not rainining\") # your code here to plot a historgram for hourly entries when it is raining\n",
    "    turnstile_weather[turnstile_weather['rain'] == 1]['ENTRIESn_hourly'].hist(alpha=0.45, label=\"rainining\") # your code here to plot a histogram for hourly entries when it is not raining\n",
    "    \n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xlabel(\"Entries per hour\")\n",
    "    plt.legend()\n",
    "    return plt\n",
    "\n",
    "entries_histogram(df_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercicio 2.7\n",
    "\n",
    "Os dados que acabou de plotar que tipo de ditribuição? Existe diferença na distribuição entre dias chuvosos e não chuvosos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta**:  \n",
    "- O retorno para ambos os casos é uma distribuiçao não-normal( assimetrica positiva )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercicio 2.8\n",
    "\n",
    "Construa uma função que que retorne:\n",
    "\n",
    "1. A média das entradas com chuva\n",
    "2. A média das entradas sem chuva\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1105.45', '1090.28', None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas\n",
    "\n",
    "def means(turnstile_weather):\n",
    "    \n",
    "    p = None\n",
    "    \n",
    "    ### YOUR CODE HERE ###\n",
    "    #Converte fog para numero inteiro \n",
    "    turnstile_weather['rain'] = pd.to_numeric(turnstile_weather['rain'], errors='coerce').fillna(0).astype(np.int64)    \n",
    "    \n",
    "    mean_rain =  turnstile_weather.groupby(['rain'])['ENTRIESn_hourly'].mean()\n",
    "    with_rain_mean = (\"%.2f\" % mean_rain[1])\n",
    "    without_rain_mean =(\"%.2f\" % mean_rain[0])\n",
    "    \n",
    "    #return mean_rain\n",
    "    \n",
    "    return with_rain_mean, without_rain_mean, p # leave this line for the grader\n",
    "\n",
    "means(df_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Responda as perguntas abaixo de acordo com a saida das suas funções:\n",
    "\n",
    "1. Qual a média das entradas com chuva?\n",
    "2. Qual a média das entradas sem chuva?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta**: \n",
    "- A média das entradas com chuva é 1105.45. \n",
    "- A média das entradas sem chuva é 1090.28."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercicio 3 - Map Reduce\n",
    "\n",
    "### *Exercicio 3.1*\n",
    "\n",
    "A entrada para esse exercício e o mesmo arquivo da seção anterior (Exercicio 2). Você pode baixar o arquivo neste link:\n",
    "\n",
    " https://s3.amazonaws.com/content.udacity-data.com/courses/ud359/turnstile_data_master_with_weather.csv\n",
    "\n",
    "Varmos criar um mapeador agora. Para cada linha de entrada, a saída do mapeador deve IMPRIMIR (não retornar) a UNIT como uma chave e o número de ENTRIESn_hourly como o valor. Separe a chave e o valor por uma guia. Por exemplo: 'R002 \\ t105105.0'\n",
    "\n",
    "Exporte seu mapeador em um arquivo chamado mapper_result.txt e envie esse arquivo juntamente com a sua submissão. O código para exportar seu mapeador já está escrito no código abaixo.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def mapper():\n",
    "    \n",
    "\n",
    "    for line in sys.stdin:\n",
    "        # your code here\n",
    "        \n",
    "        data = line.strip().split(\",\")\n",
    "        \n",
    "        if data[1] != 'UNIT' and len(data) == 22:\n",
    "            unit = data[1]\n",
    "            hour_entries = data[6]\n",
    "        \n",
    "            print(f\"{unit}\\t{hour_entries}\")\n",
    "            \n",
    "sys.stdin = open('turnstile_data_master_with_weather.csv')\n",
    "sys.stdout = open('mapper_result.txt', 'w')\n",
    "\n",
    "mapper()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exercicio 3.2*\n",
    "\n",
    "Agora crie o redutor. Dado o resultado do mapeador do exercicio anterior, o redutor deve imprimir(Não retornar) uma linha por UNIT, juntamente com o número total de ENTRIESn_hourly.Ao longo de maio (que é a duração dos nossos dados), separados por uma guia. Um exemplo de linha de saída do redutor pode ser assim: 'R001 \\ t500625.0'\n",
    "\n",
    "Você pode assumir que a entrada para o redutor está ordenada de tal forma que todas as linhas correspondentes a uma unidade particular são agrupados. No entanto a saida do redutor terá repetição pois existem lojas que aparecem em locais diferentes dos arquivos.\n",
    "\n",
    "Exporte seu redutor em um arquivo chamado reducer_result.txt e envie esse arquivo juntamente com a sua submissão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducer():\n",
    "    entriesTotal = 0\n",
    "    oldKey = None\n",
    "\n",
    "    for line in sys.stdin:\n",
    "        # your code here\n",
    "        data_mapped = line.strip().split(\"\\t\")\n",
    "        if len(data_mapped) != 2:\n",
    "            continue\n",
    "        \n",
    "        thisKey, thisEntry = data_mapped\n",
    "        \n",
    "        try:\n",
    "            thisEntry_to_f = float(thisEntry)\n",
    "            if oldKey and oldKey != thisKey:\n",
    "                print(f\"{oldKey}\\t{entriesTotal}\")\n",
    "                oldKey = thisKey\n",
    "                entriesTotal = 0\n",
    "            \n",
    "            oldKey = thisKey\n",
    "            entriesTotal += thisEntry_to_f\n",
    "        except ValueError:\n",
    "            pass\n",
    "            \n",
    "sys.stdin = open('mapper_result.txt')\n",
    "sys.stdout = open('reducer_result.txt', 'w')\n",
    "        \n",
    "reducer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referências**:\n",
    "\n",
    "    Udacity - 4. Big Data e Map Reduce (videos and texts) https://classroom.udacity.com/nanodegrees/nd025-br\n",
    "    Livro   - Bengfort/Kim, Benjamin/Jenny. Analítica de Dados com Hadoop. Primeira Edição. São Paulo, Novatec, 2016.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
